\section{Einleitung}
% Hier Deepfakes im allgemeinen Vorstellen: Welche Arten gibt es und wie werden die verbreitet?
% Aktuelles Thema als Einführung in unsere konkrete Problematik: Von Deepfake allgemein zu Teilaspekt führen den wir besprechen.
% Enden mit Forschungsfrage bzw. Ziel des Artikel: Was wollen wir zeigen, worauf wollen wir hinaus?
In der heutigen Zeit nimmt das Aufkommen und die Verbreitung von Falschmeldung zu \citep[][]{Hancock2021}.
Besonderen mehren sich die mit Hilfe von künstlicher Intelligenz erschaffene manipulierte Falschmeldungen, sogenannte Deepfakes \citep[][]{Shahzad2022}.
Der Begriff des Deepfake entsteht aus ``Deeplearning'', eine auf künstlicher Intelligenz basierter Methode des maschinellen Lernens, und ``Fake'' welcher mit Hilfe dieses ``Deeplearnings'' erstellt wird und den Menschen täuschen soll \citep[][]{Mueller2022}.
Innerhalb der Deepfakes werden z.B. Gesichter in eine Bild- oder Videodatei realistisch geschnitten, um diese Personen beliebige Worte sagen zu lassen.
So zeigt ein aktuelles Beispiel, wie Olaf Scholz eine angebliche Rede hält in der er über russische Gaslieferungen spricht \citep[][]{Klasen2022}.
Über Twitter wird die Reaktion Putins auf diese Rede von einer russischen Nachrichtenagentur geteilt \citep[Vgl.][]{Klasen2022}.
Gerade über die Kanäle der sozialen Medien wie Twitteroder Facebook, lassen sich diese Falschmeldungen heutzutage schnell und gezielt verbreiten (siehe Putin-Scholz Beispiel).
\par
Eine weitere Form des Deepfakes ist die Manipulation von Audio-Dateien.
Diese Art Deepfake oftmals von Betrügern genutzt wird, um potentielle Opfer am Telefon oder in Interviews zu täuschen, also in Echtzeit \citep[][]{Mueller2022}.
Da es bereits einige Fälle gibt, in der diese neue Art von Täuschung großen Schaden angerichtet hat \citep[Vgl.][]{Stupp2019} und die Tendenz zur Verwendung von Deepfakes zunimmt, ist die Erkennung solcher Deepfakes essentiell.
Die zeitliche Komponente bei der Erkennung spielt dabei eine besondere Rolle, denn ist der Deepfake einmal geteilt und in den Köpfen der Menschen, lassen sich Falschmeldungen nur schwierig korrigieren \citep[][]{Hancock2021}.
Dabei ist die nachträgliche Abwendung der Gefahr von Echtzeit-, also oftmals Audio-Deepfakes, dabei weitaus schwieriger als auf sozialen Medien Geteilten Video- oder Bildmaterialien \citep[][]{Shahzad2022}.
\par
Um Deepfakes als soche zu Erkennung, werden in der Literatur einige Merkmale wie z.B. die Asynchronität von Stimme und Lippenbewegung genannt \citep[][]{Appel2022}.
Auch das zu häufige Blinzeln, Kopfhaltung oder Falschstellungen von Zähnen, können ein Indiz auf einen Deepfake sein \citep[][]{Shahzad2022}.
Da die menschliche Wahrnehmung zur Erkennung eines Deepfakes allerdings limitiert ist, empfehlen Wissenschaftler den Einsatz von technischen Hilfmitteln \citep[][]{Mueller2022}.
Zwar wird sich für Maßnahmen ausgesprochen um gegen Deepfakes zu sensibilisieren, aber das wird zukünftig nicht reichen da die Technologie zur Erstellung solcher Deepfakes immer besser wird \citep[][]{Amezaga2022}.
Daher ist es unbedingt notwendig, dass die Erkennung mit technischen Hilfsmitteln weiterentwickelt werden muss.
Es gibt einige technische Lösungen zur Erkennung von Audio-Deepfakes, die ähnlich wie die Erstellung von Deepfakes auf künstlicher Intelligenz basieren, welche aber den zeitlichen Faktor nicht berücksichtigen.