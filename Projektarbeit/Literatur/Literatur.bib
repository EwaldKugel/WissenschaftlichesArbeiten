% Encoding: UTF-8

@WWW{Image2022,
	author = {IM\;NRW},
	title= {Imagebroschüre LZPD},
	url = {\url{https://lzpd.polizei.nrw/sites/default/files/2020-10/Imagebroschuere\_LZPD\_Web.pdf}},
	urldate = {25.07.2022},
	year = {2022}
}

@Misc{https://doi.org/10.13140/rg.2.2.23089.81762,
  author    = {{Shadrack Awah Buo}},
  date      = {2020},
  title     = {The Emerging Threats of Deepfake Attacks and Countermeasures},
  doi       = {10.13140/RG.2.2.23089.81762},
  language  = {en},
  publisher = {Unpublished},
}

@Misc{https://doi.org/10.48550/arxiv.2111.14203,
  author    = {Khanjani, Zahra and Watson, Gabrielle and Janeja, Vandana P.},
  date      = {2021},
  title     = {How Deep Are the Fakes? Focusing on Audio Deepfake: A Survey},
  doi       = {10.48550/ARXIV.2111.14203},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Sound (cs.SD), Artificial Intelligence (cs.AI), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering},
  publisher = {arXiv},
}

@Article{Almutairi_2022,
  author    = {Zaynab Almutairi and Hebah Elgibreen},
  title     = {A Review of Modern Audio Deepfake Detection Methods: Challenges and Future Directions},
  doi       = {10.3390/a15050155},
  number    = {5},
  pages     = {155},
  volume    = {15},
  file      = {:A Review of Modern Audio Deepfake Detection Methods_ Challenges and Future Directions.pdf:PDF},
  groups    = {Deepfake Detection},
  journal   = {Algorithms},
  month     = {may},
  publisher = {{MDPI} {AG}},
  year      = {2022},
}

@Article{Karnouskos_2020,
  author    = {Stamatis Karnouskos},
  title     = {Artificial Intelligence in Digital Media: The Era of Deepfakes},
  doi       = {10.1109/tts.2020.3001312},
  number    = {3},
  pages     = {138--147},
  volume    = {1},
  file      = {:Artificial_Intelligence_in_Digital_Media_The_Era_of_Deepfakes.pdf:PDF},
  journal   = {{IEEE} Transactions on Technology and Society},
  month     = {sep},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  year      = {2020},
}

@Article{Lim_2022,
  author    = {Suk-Young Lim and Dong-Kyu Chae and Sang-Chul Lee},
  title     = {Detecting Deepfake Voice Using Explainable Deep Learning Techniques},
  doi       = {10.3390/app12083926},
  number    = {8},
  pages     = {3926},
  volume    = {12},
  file      = {:Detecting Deepfake Voice Using Explainable Deep Learning Techniques.pdf:PDF},
  groups    = {Deepfake Detection},
  journal   = {Applied Sciences},
  month     = {apr},
  publisher = {{MDPI} {AG}},
  year      = {2022},
}

@Unpublished{Jones2022,
  author    = {Jones, Karl and Jones, Bethan},
  title     = {How robust is the United Kingdom justice system against the advance of deepfake audio and video?},
  note      = {Bethan S. Jones, Law School, University of Cumbria, UK.},
  url       = {http://infotech-bg.com/sites/default/files/2022/A05.pdf},
  abstract  = {A recent development is the application of AI to either alter or create video and audio files - called Deepfakes. The paper examines the issues arising from deepfakes, to determine how robust the UK justice system is against deepfakes. The work analyses deepfake technology, with respect to an evaluation of professional knowledge, evidential standards, and current legislation. The paper discusses difficulties presented by deepfakes, highlighting the need for methods to authenticate digital evidence, and considers what UK legal remedies can protect the justice system and public from digitally falsified evidence. The paper concludes with potential recommendations for the justice system.},
  booktitle = {InfoTech 2022 IEEE International Conference on Information Technologies},
  journal   = {Proceedings of the 36th International Conference on Information Technologies (InfoTech-2022) IEEE Conference},
  keywords  = {Audio Forensics, Deepfake, Law, Video Forensics},
  month     = {September},
  pages     = {13--24},
  year      = {2022},
}

@InProceedings{Blue2022,
  author    = {Logan Blue and Kevin Warren and Hadi Abdullah and Cassidy Gibson and Luis Vargas and Jessica O{\textquoteright}Dell and Kevin Butler and Patrick Traynor},
  booktitle = {31st USENIX Security Symposium (USENIX Security 22)},
  title     = {Who Are You (I Really Wanna Know)? Detecting Audio {DeepFakes} Through Vocal Tract Reconstruction},
  doi       = {10.17504/protocols.io.14egn7rxyv5d/v1},
  isbn      = {978-1-939133-31-1},
  pages     = {2691--2708},
  publisher = {USENIX Association},
  url       = {https://www.usenix.org/conference/usenixsecurity22/presentation/blue},
  address   = {Boston, MA},
  month     = aug,
  year      = {2022},
}

@Article{Pianese2022,
  author    = {Pianese, Alessandro and Cozzolino, Davide and Poggi, Giovanni and Verdoliva, Luisa},
  date      = {2022},
  title     = {Deepfake audio detection by speaker verification},
  doi       = {10.48550/ARXIV.2209.14098},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Sound (cs.SD), Computer Vision and Pattern Recognition (cs.CV), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering},
  publisher = {arXiv},
}

@Article{Dobber2020,
  author       = {Tom Dobber and Nadia Metoui and Damian Trilling and Natali Helberger and Claes de Vreese},
  date         = {2020-07},
  journaltitle = {The International Journal of Press/Politics},
  title        = {Do (Microtargeted) Deepfakes Have Real Effects on Political Attitudes?},
  doi          = {10.1177/1940161220944364},
  number       = {1},
  pages        = {69--91},
  volume       = {26},
  publisher    = {{SAGE} Publications},
}

@InProceedings{Mueller2022,
  author    = {M\"{u}ller, Nicolas M. and Pizzi, Karla and Williams, Jennifer},
  booktitle = {Proceedings of the 1st International Workshop on Deepfake Detection for Audio Multimedia},
  title     = {Human Perception of Audio Deepfakes},
  doi       = {10.1145/3552466.3556531},
  isbn      = {9781450394963},
  location  = {Lisboa, Portugal},
  pages     = {85–91},
  publisher = {Association for Computing Machinery},
  series    = {DDAM '22},
  url       = {https://doi.org/10.1145/3552466.3556531},
  abstract  = {The recent emergence of deepfakes has brought manipulated and generated content to the forefront of machine learning research. Automatic detection of deepfakes has seen many new machine learning techniques. Human detection capabilities, however, are far less explored. In this paper, we present results from comparing the abilities of humans and machines for detecting audio deepfakes used to imitate someone's voice. For this, we use a web-based application framework formulated as a game. Participants were asked to distinguish between real and fake audio samples. In our experiment, 410 unique users competed against a state-of-the-art AI deepfake detection algorithm for 13229 total of rounds of the game. We find that humans and deepfake detection algorithms share similar strengths and weaknesses, both struggling to detect certain types of attacks. This is in contrast to the superhuman performance of AI in many application areas such as object detection or face recognition. Concerning human success factors, we find that IT professionals have no advantage over non-professionals but native speakers have an advantage over non-native speakers. Additionally, we find that older participants tend to be more susceptible than younger ones. These insights may be helpful when designing future cybersecurity training for humans as well as developing better detection algorithms.},
  address   = {New York, NY, USA},
  keywords  = {presentation attack, deepfake, human perception, audio spoofing, games},
  numpages  = {7},
  year      = {2022},
}

@Article{Shahzad2022,
  author       = {Hina Fatima Shahzad and Furqan Rustam and Emmanuel Soriano Flores and Juan Lu{\'{\i}}s Vidal Maz{\'{o}}n and Isabel de la Torre Diez and Imran Ashraf},
  date         = {2022-06},
  journaltitle = {Sensors},
  title        = {A Review of Image Processing Techniques for Deepfakes},
  doi          = {10.3390/s22124556},
  number       = {12},
  pages        = {4556},
  volume       = {22},
  publisher    = {{MDPI} {AG}},
}



,
