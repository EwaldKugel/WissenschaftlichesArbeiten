% Encoding: UTF-8

@WWW{Image2022,
	author = {IM\;NRW},
	title= {Imagebroschüre LZPD},
	url = {\url{https://lzpd.polizei.nrw/sites/default/files/2020-10/Imagebroschuere\_LZPD\_Web.pdf}},
	urldate = {25.07.2022},
	year = {2022}
}

@Misc{Khanjani2021,
  author    = {Khanjani, Zahra and Watson, Gabrielle and Janeja, Vandana P.},
  year      = {2021},
  title     = {How Deep Are the Fakes? Focusing on Audio Deepfake: A Survey},
  doi       = {10.48550/ARXIV.2111.14203},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Sound (cs.SD), Artificial Intelligence (cs.AI), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering},
  publisher = {arXiv},
}

@Article{Almutairi2022,
  author    = {Almutairi, Zaynab and Elgibreen,  Hebah},
  title     = {A Review of Modern Audio Deepfake Detection Methods: Challenges and Future Directions},
  doi       = {10.3390/a15050155},
  number    = {5},
  pages     = {155},
  volume    = {15},
  file      = {:Artikel/Almutairi2022_A Review of Modern Audio Deepfake Detection Methods_ Challenges and Future Directions.pdf:PDF},
  groups    = {Deepfake Detection},
  journal   = {Algorithms},
  month     = {may},
  publisher = {{MDPI} {AG}},
  year      = {2022},
}

@Article{Karnouskos2020,
  author    = {Stamatis Karnouskos},
  title     = {Artificial Intelligence in Digital Media: The Era of Deepfakes},
  doi       = {10.1109/tts.2020.3001312},
  number    = {3},
  pages     = {138--147},
  volume    = {1},
  file      = {:Artikel/Karnouskos2020_Artificial_Intelligence_in_Digital_Media_The_Era_of_Deepfakes.pdf:PDF},
  journal   = {{IEEE} Transactions on Technology and Society},
  month     = {sep},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  year      = {2020},
}

@Article{Lim2022,
  author    = {Suk-Young Lim and Dong-Kyu Chae and Sang-Chul Lee},
  title     = {Detecting Deepfake Voice Using Explainable Deep Learning Techniques},
  doi       = {10.3390/app12083926},
  number    = {8},
  pages     = {3926},
  volume    = {12},
  file      = {:Artikel/Lim2022_Detecting Deepfake Voice Using Explainable Deep Learning Techniques.pdf:PDF},
  groups    = {Deepfake Detection},
  journal   = {Applied Sciences},
  month     = {apr},
  publisher = {{MDPI} {AG}},
  year      = {2022},
}

@Article{SAB2020,
  author    = {{Shadrack Awah Buo}},
  year      = {2020},
  title     = {The Emerging Threats of Deepfake Attacks and Countermeasures},
  doi       = {10.13140/RG.2.2.23089.81762},
  language  = {en},
  file      = {:Artikel/SAB2020_TheEmergingThreatsofDeepfakeAttacksandCountermeasures.pdf:PDF},
  publisher = {Unpublished},
}

@InProceedings{Blue2022,
  author    = {Logan Blue and Kevin Warren and Hadi Abdullah and Cassidy Gibson and Luis Vargas and Jessica O{\textquoteright}Dell and Kevin Butler and Patrick Traynor},
  booktitle = {31st USENIX Security Symposium (USENIX Security 22)},
  title     = {Who Are You (I Really Wanna Know)? Detecting Audio {DeepFakes} Through Vocal Tract Reconstruction},
  doi       = {10.17504/protocols.io.14egn7rxyv5d/v1},
  isbn      = {978-1-939133-31-1},
  pages     = {2691--2708},
  publisher = {USENIX Association},
  url       = {https://www.usenix.org/conference/usenixsecurity22/presentation/blue},
  address   = {Boston, MA},
  file      = {:Artikel/Blue2022_Who Are You (I Really Wanna Know)? Detecting Audio DeepFakes Through Vocal Tract Reconstruction.pdf:PDF},
  month     = aug,
  year      = {2022},
}

@Misc{Pianese2022,
  author    = {Pianese, Alessandro and Cozzolino, Davide and Poggi, Giovanni and Verdoliva, Luisa},
  title     = {Deepfake audio detection by speaker verification},
  doi       = {10.48550/ARXIV.2209.14098},
  copyright = {arXiv.org perpetual, non-exclusive license},
  file      = {:Artikel/Pianese2022_Deepfake audio detection by speaker verification.pdf:PDF},
  keywords  = {Sound (cs.SD), Computer Vision and Pattern Recognition (cs.CV), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering},
  publisher = {arXiv},
  year      = {2022},
}

@Unpublished{Jones2022,
  author    = {Jones, Karl and Jones, Bethan},
  title     = {How robust is the United Kingdom justice system against the advance of deepfake audio and video?},
  note      = {Bethan S. Jones, Law School, University of Cumbria, UK.},
  abstract  = {A recent development is the application of AI to either alter or create video and audio files - called Deepfakes. The paper examines the issues arising from deepfakes, to determine how robust the UK justice system is against deepfakes. The work analyses deepfake technology, with respect to an evaluation of professional knowledge, evidential standards, and current legislation. The paper discusses difficulties presented by deepfakes, highlighting the need for methods to authenticate digital evidence, and considers what UK legal remedies can protect the justice system and public from digitally falsified evidence. The paper concludes with potential recommendations for the justice system.},
  booktitle = {InfoTech 2022 IEEE International Conference on Information Technologies},
  file      = {:Artikel/Jones2022_HOW ROBUST IS UK AGAINST DEEPFAKE.pdf:PDF},
  journal   = {Proceedings of the 36th International Conference on Information Technologies (InfoTech-2022) IEEE Conference},
  keywords  = {Audio Forensics, Deepfake, Law, Video Forensics},
  month     = {September},
  pages     = {13--24},
  year      = {2022},
}

@Article{Godulla2021,
  author       = {Alexander Godulla and Christian P. Hoffmann and Daniel Seibert},
  year         = {2021},
  journal      = {Studies in Communication and Media},
  title        = {Dealing with deepfakes {\textendash} an interdisciplinary examination of the state of research and implications for communication studies},
  doi          = {10.5771/2192-4007-2021-1-72},
  number       = {1},
  pages        = {72--96},
  volume       = {10},
  file         = {:Artikel/Godulla2021_Dealing with deepfakes an interdisciplinary examination of the state of research and implications for communication studies.pdf:PDF},
  publisher    = {Nomos Verlag},
}

@Article{Kietzmann2020,
  author       = {Jan Kietzmann and Linda W. Lee and Ian P. McCarthy and Tim C. Kietzmann},
  date         = {2020-03},
  journal      = {Business Horizons},
  title        = {Deepfakes: Trick or treat?},
  doi          = {10.1016/j.bushor.2019.11.006},
  number       = {2},
  pages        = {135--146},
  volume       = {63},
  file         = {:Artikel/Kietzmann2020_Deepfakes Trick or treat.pdf:PDF},
  publisher    = {Elsevier {BV}},
  year		   = {2020},
}

@Article{Masood2022,
  author       = {Momina Masood and Mariam Nawaz and Khalid Mahmood Malik and Ali Javed and Aun Irtaza and Hafiz Malik},
  date         = {2022-06},
  journal      = {Applied Intelligence},
  title        = {Deepfakes generation and detection: state-of-the-art, open challenges, countermeasures, and way forward},
  doi          = {10.1007/s10489-022-03766-z},
  file         = {:Artikel/Masood2022_Deepfakes generation and detection state-of-the-art, open challenges, countermeasures, and way forward.pdf:PDF},
  publisher    = {Springer Science and Business Media {LLC}},
  year		   = {2022},
}

@Article{Appel2022,
  author       = {Markus Appel and Fabian Prietzel},
  date         = {2022-07},
  journal      = {Journal of Computer-Mediated Communication},
  title        = {The detection of political deepfakes},
  doi          = {10.1093/jcmc/zmac008},
  editor       = {Nicole Krämer},
  number       = {4},
  volume       = {27},
  file         = {:Artikel/Appel2022_The detection of political deepfakes.pdf:PDF},
  publisher    = {Oxford University Press ({OUP})},
  year		   = {2022},
}

@Article{Shahzad2022,
  author       = {Hina Fatima Shahzad and Furqan Rustam and Emmanuel Soriano Flores and Juan Lu{\'{\i}}s Vidal Maz{\'{o}}n and Isabel de la Torre Diez and Imran Ashraf},
  date         = {2022-06},
  journal      = {Sensors},
  title        = {A Review of Image Processing Techniques for Deepfakes},
  doi          = {10.3390/s22124556},
  number       = {12},
  pages        = {4556},
  volume       = {22},
  file         = {:Artikel/Shahzad2022 A Review of Image Processing Techniques for Deepfakes.pdf:PDF},
  publisher    = {{MDPI} {AG}},
  year		   = {2022},
}

@Article{Dobber2020,
  author       = {Dobber, Tom and Metoui, Nadia and Trilling, Damian and Helberger, Natali and de Vreese, Claes},
  date         = {2020-07},
  journal	   = {The International Journal of Press/Politics},
  title        = {Do (Microtargeted) Deepfakes Have Real Effects on Political Attitudes?},
  doi          = {10.1177/1940161220944364},
  number       = {1},
  pages        = {69--91},
  volume       = {26},
  file         = {:Artikel/Dobber2020 Do (Microtargeted) Deepfakes Have Real Effects on Political Attitudes.pdf:PDF},
  publisher    = {{SAGE} Publications},
  year         = {2021},
}

@InProceedings{Mueller2022,
  author    = {M\"{u}ller, Nicolas M. and Pizzi, Karla and Williams, Jennifer},
  booktitle = {Proceedings of the 1st International Workshop on Deepfake Detection for Audio Multimedia},
  title     = {Human Perception of Audio Deepfakes},
  doi       = {10.1145/3552466.3556531},
  isbn      = {9781450394963},
  location  = {Lisboa, Portugal},
  pages     = {85–91},
  publisher = {Association for Computing Machinery},
  series    = {DDAM '22},
  abstract  = {The recent emergence of deepfakes has brought manipulated and generated content to the forefront of machine learning research. Automatic detection of deepfakes has seen many new machine learning techniques. Human detection capabilities, however, are far less explored. In this paper, we present results from comparing the abilities of humans and machines for detecting audio deepfakes used to imitate someone's voice. For this, we use a web-based application framework formulated as a game. Participants were asked to distinguish between real and fake audio samples. In our experiment, 410 unique users competed against a state-of-the-art AI deepfake detection algorithm for 13229 total of rounds of the game. We find that humans and deepfake detection algorithms share similar strengths and weaknesses, both struggling to detect certain types of attacks. This is in contrast to the superhuman performance of AI in many application areas such as object detection or face recognition. Concerning human success factors, we find that IT professionals have no advantage over non-professionals but native speakers have an advantage over non-native speakers. Additionally, we find that older participants tend to be more susceptible than younger ones. These insights may be helpful when designing future cybersecurity training for humans as well as developing better detection algorithms.},
  address   = {New York, NY, USA},
  file      = {:Artikel/Mueller2022 Human Perception of Audio Deepfakes.pdf:PDF},
  keywords  = {presentation attack, deepfake, human perception, audio spoofing, games},
  numpages  = {7},
  year      = {2022},
}

@Article{Lee2019,
  author       = {Terry Lee},
  date         = {2019-07},
  journal      = {Public Administration and Policy},
  title        = {The global rise of {\textquotedblleft}fake news{\textquotedblright} and the threat to democratic elections in the {USA}},
  doi          = {10.1108/pap-04-2019-0008},
  number       = {1},
  pages        = {15--24},
  volume       = {22},
  publisher    = {Emerald},
  year      = {2019},
}

@Article{Papakyriakopoulos2017,
  author       = {Orestis Papakyriakopoulos and Morteza Shahrezaye and Andree Thieltges and Juan Carlos Medina Serrano and Simon Hegelich},
  date         = {2017-06},
  journal      = {Informatik-Spektrum},
  title        = {Social Media und Microtargeting in Deutschland},
  doi          = {10.1007/s00287-017-1051-4},
  number       = {4},
  pages        = {327--335},
  volume       = {40},
  publisher    = {Springer Science and Business Media {LLC}},
  year      = {2017},
}

@Article{Hancock2021,
  author       = {Jeffrey T. Hancock and Jeremy N. Bailenson},
  date         = {2021-03},
  journal      = {Cyberpsychology, Behavior, and Social Networking},
  title        = {The Social Impact of Deepfakes},
  doi          = {10.1089/cyber.2021.29208.jth},
  number       = {3},
  pages        = {149--152},
  volume       = {24},
  publisher    = {Mary Ann Liebert Inc},  
  year      = {2021},
}

@InProceedings{Amezaga2022,
  author    = {Naroa Amezaga and Jeremy Hajek},
  booktitle = {The 23rd Annual Conference on Information Technology Education},
  date      = {2022-09},
  title     = {Availability of Voice Deepfake Technology and its Impact for Good and Evil},
  doi       = {10.1145/3537674.3554742},
  isbn      = {9781450393911},
  location  = {Chicago, IL, USA},
  pages     = {23–28},
  publisher = {{ACM}},
  series    = {SIGITE '22},
  url       = {https://doi.org/10.1145/3537674.3554742},
  abstract  = {Artificial Intelligence and especially Machine Learning and Deep Learning techniques are increasingly populating today's technological and social landscape. These advancements have overwhelmingly contributed to the development of Speech Synthesis, also known as Text-To-Speech, where speech is artificially produced from text by means of computer technology [1]. But currently, there is a fundamental common drawback: unnatural, robotic and impersonal synthesized voices [2].So, what happens when the robotic computer voice no longer sounds like a computer, but sounds like you? That's where Voice Cloning technology comes into play, which allows one to generate an artificial speech that resembles a targeted human voice. This new practice offers many benefits, but with its development, the generation of fake voices and videos, known as “deepfakes”, has risen, causing a loss of trust and greater fear towards technology [3].In this way, the objective of this paper is to analyze the availability of voice deepfake technologies, its ease of construction and its impact for good and evil. We chose to focus on the educational field by implementing a “deepfake professor” via a survey of readily available voice deepfake technologies. The goal is then to demonstrate the potential capabilities for good and for evil that need to be considered with this technology, so we also conduct an analysis about the misuse, the current regulation, and the future of it.The results of the case study show that it is possible to clone someone's voice with a standard laptop, with no need of high-performance computing resources and based on just a few seconds of reference audio, which creates a superior user experience, but at the same time, reveals how easily can anyone have access to voice cloning. This expresses very well the importance of the new challenges opened by this potential technology and the need of safeguarding and regulation that future generations will have to deal with. There is no doubt that to understand the dynamics and impact of voice cloning and to reach more solid conclusions, future research is needed.},
  address   = {New York, NY, USA},
  numpages  = {6},
  year      = {2022},
}

@misc{Kawa2022,
  doi = {10.48550/ARXIV.2210.06105},
  
  url = {https://arxiv.org/abs/2210.06105},
  
  author = {Kawa, Piotr and Plata, Marcin and Syga, Piotr},
  
  keywords = {Sound (cs.SD), Machine Learning (cs.LG), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  
  title = {SpecRNet: Towards Faster and More Accessible Audio DeepFake Detection},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@Article{Khochare2021,
  author    = {Janavi Khochare and Chaitali Joshi and Bakul Yenarkar and Shraddha Suratkar and Faruk Kazi},
  title     = {A Deep Learning Framework for Audio Deepfake Detection},
  doi       = {10.1007/s13369-021-06297-w},
  number    = {3},
  pages     = {3447--3458},
  volume    = {47},
  journal   = {Arabian Journal for Science and Engineering},
  month     = {nov},
  publisher = {Springer Science and Business Media {LLC}},
  year      = {2021},
}

@Article{Liu2022,
  author    = {Liu, Xuechen and Wang, Xin and Sahidullah, Md and Patino, Jose and Delgado, Héctor and Kinnunen, Tomi and Todisco, Massimiliano and Yamagishi, Junichi and Evans, Nicholas and Nautsch, Andreas and Lee, Kong Aik},
  title     = {ASVspoof 2021: Towards Spoofed and Deepfake Speech Detection in the Wild},
  doi       = {10.48550/ARXIV.2210.02437},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords  = {Sound (cs.SD), Cryptography and Security (cs.CR), Multimedia (cs.MM), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  publisher = {arXiv},
  year      = {2022},
}

@Article{Ardila2019,
  author    = {Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M. and Weber, Gregor},
  title     = {Common Voice: A Massively-Multilingual Speech Corpus},
  doi       = {10.48550/ARXIV.1912.06670},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  year      = {2019},
}

@Article{Reimao2019,
  author    = {Ricardo Reimao and Vassilios Tzerpos},
  title     = {{FoR}: A Dataset for Synthetic Speech Detection},
  doi       = {10.1109/sped.2019.8906599},
  booktitle = {2019 International Conference on Speech Technology and Human-Computer Dialogue ({SpeD})},
  month     = {oct},
  publisher = {{IEEE}},
  year      = {2019},
}

@Article{Yamagishi2021,
  author    = {Junichi Yamagishi and Xin Wang and Massimiliano Todisco and Md Sahidullah and Jose Patino and Andreas Nautsch and Xuechen Liu and Kong Aik Lee and Tomi Kinnunen and Nicholas Evans and H{\'{e}}ctor Delgado},
  title     = {{ASVspoof} 2021: accelerating progress in spoofed and deepfake speech detection},
  doi       = {10.21437/asvspoof.2021-8},
  booktitle = {2021 Edition of the Automatic Speaker Verification and Spoofing Countermeasures Challenge},
  month     = {sep},
  publisher = {{ISCA}},
  year      = {2021},
}

@Article{Ballesteros2021,
  author    = {Dora M. Ballesteros and Yohanna Rodriguez-Ortega and Diego Renza and Gonzalo Arce},
  title     = {Deep4SNet: deep learning for fake speech classification},
  doi       = {10.1016/j.eswa.2021.115465},
  pages     = {115465},
  volume    = {184},
  journal   = {Expert Systems with Applications},
  month     = {dec},
  publisher = {Elsevier {BV}},
  year      = {2021},
}

@Comment{jabref-meta: databaseType:biblatex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Deepfake Detection\;0\;0\;0x8a8a8aff\;\;\;;
}

,
