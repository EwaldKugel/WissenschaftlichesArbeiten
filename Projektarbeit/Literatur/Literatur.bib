% Encoding: UTF-8

@WWW{Image2022,
	author = {IM\;NRW},
	title= {Imagebroschüre LZPD},
	url = {\url{https://lzpd.polizei.nrw/sites/default/files/2020-10/Imagebroschuere\_LZPD\_Web.pdf}},
	urldate = {25.07.2022},
	year = {2022}
}

@Misc{Khanjani2021,
  author    = {Khanjani, Zahra and Watson, Gabrielle and Janeja, Vandana P.},
  year      = {2021},
  title     = {How Deep Are the Fakes? Focusing on Audio Deepfake: A Survey},
  doi       = {10.48550/ARXIV.2111.14203},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Sound (cs.SD), Artificial Intelligence (cs.AI), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering},
  publisher = {arXiv},
}

@Article{Almutairi2022,
  author    = {Almutairi, Zaynab and Elgibreen,  Hebah},
  title     = {A Review of Modern Audio Deepfake Detection Methods: Challenges and Future Directions},
  doi       = {10.3390/a15050155},
  number    = {5},
  pages     = {155},
  volume    = {15},
  file      = {:Artikel/Almutairi2022_A Review of Modern Audio Deepfake Detection Methods_ Challenges and Future Directions.pdf:PDF},
  groups    = {Deepfake Detection},
  journal   = {Algorithms},
  month     = {may},
  publisher = {{MDPI} {AG}},
  year      = {2022},
}

@Article{Karnouskos2020,
  author    = {Stamatis Karnouskos},
  title     = {Artificial Intelligence in Digital Media: The Era of Deepfakes},
  doi       = {10.1109/tts.2020.3001312},
  number    = {3},
  pages     = {138--147},
  volume    = {1},
  file      = {:Artikel/Karnouskos2020_Artificial_Intelligence_in_Digital_Media_The_Era_of_Deepfakes.pdf:PDF},
  journal   = {{IEEE} Transactions on Technology and Society},
  month     = {sep},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  year      = {2020},
}

@Article{Lim2022,
  author    = {Suk-Young Lim and Dong-Kyu Chae and Sang-Chul Lee},
  title     = {Detecting Deepfake Voice Using Explainable Deep Learning Techniques},
  doi       = {10.3390/app12083926},
  number    = {8},
  pages     = {3926},
  volume    = {12},
  file      = {:Artikel/Lim2022_Detecting Deepfake Voice Using Explainable Deep Learning Techniques.pdf:PDF},
  groups    = {Deepfake Detection},
  journal   = {Applied Sciences},
  month     = {apr},
  publisher = {{MDPI} {AG}},
  year      = {2022},
}

@Article{SAB2020,
  author    = {{Shadrack Awah Buo}},
  year      = {2020},
  title     = {The Emerging Threats of Deepfake Attacks and Countermeasures},
  doi       = {10.13140/RG.2.2.23089.81762},
  language  = {en},
  file      = {:Artikel/SAB2020_TheEmergingThreatsofDeepfakeAttacksandCountermeasures.pdf:PDF},
  publisher = {Unpublished},
}

@InProceedings{Blue2022,
  author    = {Logan Blue and Kevin Warren and Hadi Abdullah and Cassidy Gibson and Luis Vargas and Jessica O{\textquoteright}Dell and Kevin Butler and Patrick Traynor},
  booktitle = {31st USENIX Security Symposium (USENIX Security 22)},
  title     = {Who Are You (I Really Wanna Know)? Detecting Audio {DeepFakes} Through Vocal Tract Reconstruction},
  doi       = {10.17504/protocols.io.14egn7rxyv5d/v1},
  isbn      = {978-1-939133-31-1},
  pages     = {2691--2708},
  publisher = {USENIX Association},
  url       = {https://www.usenix.org/conference/usenixsecurity22/presentation/blue},
  address   = {Boston, MA},
  file      = {:Artikel/Blue2022_Who Are You (I Really Wanna Know)? Detecting Audio DeepFakes Through Vocal Tract Reconstruction.pdf:PDF},
  month     = aug,
  year      = {2022},
}

@Misc{Pianese2022,
  author    = {Pianese, Alessandro and Cozzolino, Davide and Poggi, Giovanni and Verdoliva, Luisa},
  title     = {Deepfake audio detection by speaker verification},
  doi       = {10.48550/ARXIV.2209.14098},
  copyright = {arXiv.org perpetual, non-exclusive license},
  file      = {:Artikel/Pianese2022_Deepfake audio detection by speaker verification.pdf:PDF},
  keywords  = {Sound (cs.SD), Computer Vision and Pattern Recognition (cs.CV), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering},
  publisher = {arXiv},
  year      = {2022},
}

@Unpublished{Jones2022,
  author    = {Jones, Karl and Jones, Bethan},
  title     = {How robust is the United Kingdom justice system against the advance of deepfake audio and video?},
  note      = {Bethan S. Jones, Law School, University of Cumbria, UK.},
  abstract  = {A recent development is the application of AI to either alter or create video and audio files - called Deepfakes. The paper examines the issues arising from deepfakes, to determine how robust the UK justice system is against deepfakes. The work analyses deepfake technology, with respect to an evaluation of professional knowledge, evidential standards, and current legislation. The paper discusses difficulties presented by deepfakes, highlighting the need for methods to authenticate digital evidence, and considers what UK legal remedies can protect the justice system and public from digitally falsified evidence. The paper concludes with potential recommendations for the justice system.},
  booktitle = {InfoTech 2022 IEEE International Conference on Information Technologies},
  file      = {:Artikel/Jones2022_HOW ROBUST IS UK AGAINST DEEPFAKE.pdf:PDF},
  journal   = {Proceedings of the 36th International Conference on Information Technologies (InfoTech-2022) IEEE Conference},
  keywords  = {Audio Forensics, Deepfake, Law, Video Forensics},
  month     = {September},
  pages     = {13--24},
  year      = {2022},
}

@Article{Godulla2021,
  author       = {Alexander Godulla and Christian P. Hoffmann and Daniel Seibert},
  year         = {2021},
  journaltitle = {Studies in Communication and Media},
  title        = {Dealing with deepfakes {\textendash} an interdisciplinary examination of the state of research and implications for communication studies},
  doi          = {10.5771/2192-4007-2021-1-72},
  number       = {1},
  pages        = {72--96},
  volume       = {10},
  file         = {:Artikel/Godulla2021_Dealing with deepfakes an interdisciplinary examination of the state of research and implications for communication studies.pdf:PDF},
  publisher    = {Nomos Verlag},
}

@Article{Kietzmann2020,
  author       = {Jan Kietzmann and Linda W. Lee and Ian P. McCarthy and Tim C. Kietzmann},
  date         = {2020-03},
  journaltitle = {Business Horizons},
  title        = {Deepfakes: Trick or treat?},
  doi          = {10.1016/j.bushor.2019.11.006},
  number       = {2},
  pages        = {135--146},
  volume       = {63},
  file         = {:Artikel/Kietzmann2020_Deepfakes Trick or treat.pdf:PDF},
  publisher    = {Elsevier {BV}},
  year		   = {2020},
}

@Article{Masood2022,
  author       = {Momina Masood and Mariam Nawaz and Khalid Mahmood Malik and Ali Javed and Aun Irtaza and Hafiz Malik},
  date         = {2022-06},
  journaltitle = {Applied Intelligence},
  title        = {Deepfakes generation and detection: state-of-the-art, open challenges, countermeasures, and way forward},
  doi          = {10.1007/s10489-022-03766-z},
  file         = {:Artikel/Masood2022_Deepfakes generation and detection state-of-the-art, open challenges, countermeasures, and way forward.pdf:PDF},
  publisher    = {Springer Science and Business Media {LLC}},
  year		   = {2022},
}

@Article{Appel2022,
  author       = {Markus Appel and Fabian Prietzel},
  date         = {2022-07},
  journaltitle = {Journal of Computer-Mediated Communication},
  title        = {The detection of political deepfakes},
  doi          = {10.1093/jcmc/zmac008},
  editor       = {Nicole Krämer},
  number       = {4},
  volume       = {27},
  file         = {:Artikel/Appel2022_The detection of political deepfakes.pdf:PDF},
  publisher    = {Oxford University Press ({OUP})},
  year		   = {2022},
}

@Article{Shahzad2022,
  author       = {Hina Fatima Shahzad and Furqan Rustam and Emmanuel Soriano Flores and Juan Lu{\'{\i}}s Vidal Maz{\'{o}}n and Isabel de la Torre Diez and Imran Ashraf},
  date         = {2022-06},
  journaltitle = {Sensors},
  title        = {A Review of Image Processing Techniques for Deepfakes},
  doi          = {10.3390/s22124556},
  number       = {12},
  pages        = {4556},
  volume       = {22},
  file         = {:Artikel/Shahzad2022 A Review of Image Processing Techniques for Deepfakes.pdf:PDF},
  publisher    = {{MDPI} {AG}},
  year		   = {2022},
}

@Article{Dobber2020,
  author       = {Dobber, Tom and Metoui, Nadia and Trilling, Damian and Helberger, Natali and de Vreese, Claes},
  date         = {2020-07},
  journal	   = {The International Journal of Press/Politics},
  title        = {Do (Microtargeted) Deepfakes Have Real Effects on Political Attitudes?},
  doi          = {10.1177/1940161220944364},
  number       = {1},
  pages        = {69--91},
  volume       = {26},
  file         = {:Artikel/Dobber2020 Do (Microtargeted) Deepfakes Have Real Effects on Political Attitudes.pdf:PDF},
  publisher    = {{SAGE} Publications},
  year         = {2021},
}

@InProceedings{Mueller2022,
  author    = {M\"{u}ller, Nicolas M. and Pizzi, Karla and Williams, Jennifer},
  booktitle = {Proceedings of the 1st International Workshop on Deepfake Detection for Audio Multimedia},
  title     = {Human Perception of Audio Deepfakes},
  doi       = {10.1145/3552466.3556531},
  isbn      = {9781450394963},
  location  = {Lisboa, Portugal},
  pages     = {85–91},
  publisher = {Association for Computing Machinery},
  series    = {DDAM '22},
  abstract  = {The recent emergence of deepfakes has brought manipulated and generated content to the forefront of machine learning research. Automatic detection of deepfakes has seen many new machine learning techniques. Human detection capabilities, however, are far less explored. In this paper, we present results from comparing the abilities of humans and machines for detecting audio deepfakes used to imitate someone's voice. For this, we use a web-based application framework formulated as a game. Participants were asked to distinguish between real and fake audio samples. In our experiment, 410 unique users competed against a state-of-the-art AI deepfake detection algorithm for 13229 total of rounds of the game. We find that humans and deepfake detection algorithms share similar strengths and weaknesses, both struggling to detect certain types of attacks. This is in contrast to the superhuman performance of AI in many application areas such as object detection or face recognition. Concerning human success factors, we find that IT professionals have no advantage over non-professionals but native speakers have an advantage over non-native speakers. Additionally, we find that older participants tend to be more susceptible than younger ones. These insights may be helpful when designing future cybersecurity training for humans as well as developing better detection algorithms.},
  address   = {New York, NY, USA},
  file      = {:Artikel/Mueller2022 Human Perception of Audio Deepfakes.pdf:PDF},
  keywords  = {presentation attack, deepfake, human perception, audio spoofing, games},
  numpages  = {7},
  year      = {2022},
}

@Article{Lee2019,
  author       = {Terry Lee},
  date         = {2019-07},
  journaltitle = {Public Administration and Policy},
  title        = {The global rise of {\textquotedblleft}fake news{\textquotedblright} and the threat to democratic elections in the {USA}},
  doi          = {10.1108/pap-04-2019-0008},
  number       = {1},
  pages        = {15--24},
  volume       = {22},
  publisher    = {Emerald},
  year      = {2019},
}

@Comment{jabref-meta: databaseType:biblatex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Deepfake Detection\;0\;0\;0x8a8a8aff\;\;\;;
}

,
