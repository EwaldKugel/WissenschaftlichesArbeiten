\subsection{Forschungsnische}
Aktuelle Literatur zum Thema Deepfake und speziell Audio Deepfake kann grob in die Bereiche Risikobetrachtung und -untersuchung und technische Betrachtung aufgeteilt werden.
Bei der Risikobetrachtung werden Untersuchungen durchgeführt, die beispielsweise die Beeinflussbarkeit von Wählern durch Deepfakes  \citep[vgl.][]{Dobber2020} oder allgemein die Sensibilität von Bevölkerungsgruppen für Deepfakes untersuchen \citep[vgl.][]{Mueller2022}.
In der technischen Betrachtung gibt es aktuell eine Reihe von Übersichtsartikeln über diverse Detektionsmethoden für Audio Deepfakes \citep[vgl.][]{Masood2022,Khanjani2021,Almutairi2022}.
Hier liegt der Fokus darauf, verschiedene Methoden sowohl auf Effektivität als auch auf Effizienz zu überprüfen und Vorschläge für die weitere Forschung abzugeben.

Allen Artikeln ist dabei gemein, dass zunächst die Relevanz der Problematik an Beispielen oder theoretischen Überlegungen hervorgehoben wird.
Dabei gibt es durchaus auch Artikel, die auf positive Aspekte von beispielsweise Text-to-Speech (TTS) Technologien (Voice Assistant) oder auf harmlose Anwendungen von Deepfakes in der Filmindustrie eingehen.
Die Gefahren wie die Beeinflussung von politischen Wahlen, Telefonbetrug im teilweise großen Stil \citep[vgl.][]{} oder vergleichsweise kleiner Betrug im privaten Umfeld \citep[][]{} stehen jedoch bei allen Artikeln im Vordergrund.
Daraus wird hauptsächlich die Notwendigkeit der Forschung auf dem Gebiet der Deepfake Detection abgeleitet, nur wenige Artikel beschäftigen sich mit dem allgemeinen Vorgehen bzw. dem allgemeinen Umgang mit Deepfakes \citep[][]{}.

Da die Problematik wie oben gezeigt nicht nur alle Altersklassen sondern vor allem über gesellschaftliche Schichten, Berufe bis zu geopolitischen und zwischenstaatlichen Beziehungen so ziemlich jeden betrifft ist das ein besonders wichtiger Punkt.
Es muss die Frage gestellt werden, ob rein technischer Fortschritt in der Erkennung von Deepfakes ausreicht, um ausreichend dagegen vorgehen zu können.